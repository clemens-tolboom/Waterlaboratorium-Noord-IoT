{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2>Exploration (get a very first feeling of the data)</h2>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "This is a copy of `wico-explore01.ipynb` for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name='zwst (mg/l)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kennisnetwerk_data_WWTPpopulaties_WLN.xlsx\r\n",
      "Kennisnetwerk_procesdata_kwaliteitsdata_WLN.xlsx\r\n",
      "README.MD\r\n",
      "begeleidende tekst data casus WLN.docx\r\n",
      "uurgeg_277_2011-2020.txt\r\n",
      "uurgeg_277_2011-2020_KNMI_Lauwersoog.zip\r\n",
      "uurgeg_280_2011-2020.txt\r\n",
      "uurgeg_280_2011-2020_KNMI_Eelde.zip\r\n",
      "uurgeg_285_2011-2020.txt\r\n",
      "uurgeg_285_2011-2020_KNMI_Huibertgat.zip\r\n",
      "uurgeg_286_2011-2020.txt\r\n",
      "uurgeg_286_2011-2020_KNMI_Nieuw_Beerta.zip\r\n"
     ]
    }
   ],
   "source": [
    "XLS_DIR='../../Waterlaboratorium-Noord-IoT/Data/'\n",
    "%ls $XLS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-read-data.ipynb\r\n",
      "Pipfile\r\n",
      "Pipfile.lock\r\n",
      "README.MD\r\n",
      "altair-data-a7058e0c6f5119308fc517a83fa03339.json\r\n",
      "altair-test.ipynb\r\n",
      "clemens-01.ipynb\r\n",
      "clemens-02.ipynb\r\n",
      "clemens-03.ipynb\r\n",
      "clemens-04.ipynb\r\n",
      "\u001b[34mdata\u001b[m\u001b[m/\r\n",
      "\u001b[34mdocs\u001b[m\u001b[m/\r\n",
      "inne-01.ipynb\r\n",
      "read_and_explore.ipynb\r\n",
      "wico-explore01.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "# This result in current dir as $DATA_DIR is empty\n",
    "%ls $DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mKennisnetwerk_procesdata_kwaliteitsdata_WLN\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "CSV_DIR='../../ds-wln/datasets/'\n",
    "%ls $CSV_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_XLS=False\n",
    "\n",
    "if USE_XLS:\n",
    "    # This will result in XLRDError: Can't find workbook in OLE2 compound document\n",
    "    orig_influent = pd.read_excel(XLS_DIR + \"Kennisnetwerk_procesdata_kwaliteitsdata_WLN.xlsx\", sheet_name='Influent lab analyses')\n",
    "    orig_effluent=pd.read_excel(DATA_DIR + \"Kennisnetwerk_procesdata_kwaliteitsdata_WLN.xlsx\", sheet_name='effl. lab analyses')\n",
    "\n",
    "else:\n",
    "    orig_influent = pd.read_csv(CSV_DIR + 'Kennisnetwerk_procesdata_kwaliteitsdata_WLN/' + 'Influent lab analyses.csv', sep=',', decimal ='.')\n",
    "    orig_effluent = pd.read_csv(CSV_DIR + 'Kennisnetwerk_procesdata_kwaliteitsdata_WLN/' + 'effl. lab analyses.csv', sep=',', decimal ='.')\n",
    "    # We need to convert date field(s) from m/d/y as these are exported by CSV and not by Excel above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch Datum and our target column_name\n",
    "orig_influent = orig_influent[['Datum', column_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datum</th>\n",
       "      <th>zwst (mg/l)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/01/14</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/06/14</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/11/14</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/16/14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/21/14</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Datum zwst (mg/l)\n",
       "0  10/01/14          17\n",
       "1  10/06/14           7\n",
       "2  10/11/14          39\n",
       "3  10/16/14          15\n",
       "4  10/21/14          11"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_effluent=orig_effluent[['Datum', column_name]]\n",
    "\n",
    "orig_effluent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datum</th>\n",
       "      <th>zwst (mg/l)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-10-01</th>\n",
       "      <td>10/01/14</td>\n",
       "      <td>172.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-10-06</th>\n",
       "      <td>10/06/14</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-10-11</th>\n",
       "      <td>10/11/14</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-10-16</th>\n",
       "      <td>10/16/14</td>\n",
       "      <td>174.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-10-21</th>\n",
       "      <td>10/21/14</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-10-26</th>\n",
       "      <td>10/26/14</td>\n",
       "      <td>113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-10-31</th>\n",
       "      <td>10/31/14</td>\n",
       "      <td>207.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11-05</th>\n",
       "      <td>11/05/14</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11-10</th>\n",
       "      <td>11/10/14</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11-15</th>\n",
       "      <td>11/15/14</td>\n",
       "      <td>161.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11-20</th>\n",
       "      <td>11/20/14</td>\n",
       "      <td>171.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11-25</th>\n",
       "      <td>11/25/14</td>\n",
       "      <td>189.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11-30</th>\n",
       "      <td>11/30/14</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-05</th>\n",
       "      <td>12/05/14</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-13</th>\n",
       "      <td>12/13/14</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-15</th>\n",
       "      <td>12/15/14</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-20</th>\n",
       "      <td>12/20/14</td>\n",
       "      <td>1037.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-25</th>\n",
       "      <td>12/25/14</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31</th>\n",
       "      <td>12/31/14</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-04</th>\n",
       "      <td>01/04/15</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-09</th>\n",
       "      <td>01/09/15</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-14</th>\n",
       "      <td>01/14/15</td>\n",
       "      <td>322.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-22</th>\n",
       "      <td>01/22/15</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-24</th>\n",
       "      <td>01/24/15</td>\n",
       "      <td>218.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-29</th>\n",
       "      <td>01/29/15</td>\n",
       "      <td>156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-03</th>\n",
       "      <td>02/03/15</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-08</th>\n",
       "      <td>02/08/15</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-13</th>\n",
       "      <td>02/13/15</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-18</th>\n",
       "      <td>02/18/15</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-20</th>\n",
       "      <td>02/20/15</td>\n",
       "      <td>235.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-07</th>\n",
       "      <td>04/07/17</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-17</th>\n",
       "      <td>04/17/17</td>\n",
       "      <td>113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-27</th>\n",
       "      <td>04/27/17</td>\n",
       "      <td>109.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-07</th>\n",
       "      <td>05/07/17</td>\n",
       "      <td>112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-17</th>\n",
       "      <td>05/17/17</td>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-27</th>\n",
       "      <td>05/27/17</td>\n",
       "      <td>123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-06</th>\n",
       "      <td>06/06/17</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-16</th>\n",
       "      <td>06/16/17</td>\n",
       "      <td>126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-26</th>\n",
       "      <td>06/26/17</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-07</th>\n",
       "      <td>07/07/17</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-16</th>\n",
       "      <td>07/16/17</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-26</th>\n",
       "      <td>07/26/17</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-05</th>\n",
       "      <td>08/05/17</td>\n",
       "      <td>161.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-15</th>\n",
       "      <td>08/15/17</td>\n",
       "      <td>276.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-25</th>\n",
       "      <td>08/25/17</td>\n",
       "      <td>77.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-04</th>\n",
       "      <td>09/04/17</td>\n",
       "      <td>146.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-14</th>\n",
       "      <td>09/14/17</td>\n",
       "      <td>91.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-26</th>\n",
       "      <td>09/26/17</td>\n",
       "      <td>72.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-04</th>\n",
       "      <td>10/04/17</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-14</th>\n",
       "      <td>10/14/17</td>\n",
       "      <td>170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-24</th>\n",
       "      <td>10/24/17</td>\n",
       "      <td>306.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-03</th>\n",
       "      <td>11/03/17</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-13</th>\n",
       "      <td>11/13/17</td>\n",
       "      <td>164.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-23</th>\n",
       "      <td>11/23/17</td>\n",
       "      <td>170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-03</th>\n",
       "      <td>12/03/17</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-13</th>\n",
       "      <td>12/13/17</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-25</th>\n",
       "      <td>12/25/17</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>01/02/18</td>\n",
       "      <td>54.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-17</th>\n",
       "      <td>01/17/18</td>\n",
       "      <td>216.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-22</th>\n",
       "      <td>01/22/18</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Datum  zwst (mg/l)\n",
       "date                             \n",
       "2014-10-01  10/01/14        172.0\n",
       "2014-10-06  10/06/14         91.0\n",
       "2014-10-11  10/11/14         66.0\n",
       "2014-10-16  10/16/14        174.0\n",
       "2014-10-21  10/21/14         74.0\n",
       "2014-10-26  10/26/14        113.0\n",
       "2014-10-31  10/31/14        207.0\n",
       "2014-11-05  11/05/14         68.0\n",
       "2014-11-10  11/10/14         54.0\n",
       "2014-11-15  11/15/14        161.0\n",
       "2014-11-20  11/20/14        171.0\n",
       "2014-11-25  11/25/14        189.0\n",
       "2014-11-30  11/30/14         39.0\n",
       "2014-12-05  12/05/14         52.0\n",
       "2014-12-13  12/13/14         92.0\n",
       "2014-12-15  12/15/14         49.0\n",
       "2014-12-20  12/20/14       1037.0\n",
       "2014-12-25  12/25/14         41.0\n",
       "2014-12-31  12/31/14         40.0\n",
       "2015-01-04  01/04/15         90.0\n",
       "2015-01-09  01/09/15        101.0\n",
       "2015-01-14  01/14/15        322.0\n",
       "2015-01-22  01/22/15         37.0\n",
       "2015-01-24  01/24/15        218.0\n",
       "2015-01-29  01/29/15        156.0\n",
       "2015-02-03  02/03/15         35.0\n",
       "2015-02-08  02/08/15         96.0\n",
       "2015-02-13  02/13/15         46.0\n",
       "2015-02-18  02/18/15         52.0\n",
       "2015-02-20  02/20/15        235.0\n",
       "...              ...          ...\n",
       "2017-04-07  04/07/17         73.0\n",
       "2017-04-17  04/17/17        113.0\n",
       "2017-04-27  04/27/17        109.0\n",
       "2017-05-07  05/07/17        112.0\n",
       "2017-05-17  05/17/17        138.0\n",
       "2017-05-27  05/27/17        123.0\n",
       "2017-06-06  06/06/17         66.0\n",
       "2017-06-16  06/16/17        126.0\n",
       "2017-06-26  06/26/17         87.0\n",
       "2017-07-07  07/07/17         85.0\n",
       "2017-07-16  07/16/17        124.0\n",
       "2017-07-26  07/26/17         57.0\n",
       "2017-08-05  08/05/17        161.0\n",
       "2017-08-15  08/15/17        276.0\n",
       "2017-08-25  08/25/17         77.4\n",
       "2017-09-04  09/04/17        146.0\n",
       "2017-09-14  09/14/17         91.8\n",
       "2017-09-26  09/26/17         72.1\n",
       "2017-10-04  10/04/17         72.0\n",
       "2017-10-14  10/14/17        170.0\n",
       "2017-10-24  10/24/17        306.0\n",
       "2017-11-03  11/03/17         48.0\n",
       "2017-11-13  11/13/17        164.0\n",
       "2017-11-23  11/23/17        170.0\n",
       "2017-12-03  12/03/17         61.0\n",
       "2017-12-13  12/13/17         79.0\n",
       "2017-12-25  12/25/17        107.0\n",
       "2018-01-02  01/02/18         54.4\n",
       "2018-01-17  01/17/18        216.0\n",
       "2018-01-22  01/22/18        119.0\n",
       "\n",
       "[170 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "influent = orig_influent.copy()\n",
    "\n",
    "# opruimen maffe velden\n",
    "effluent = orig_effluent.copy()\n",
    "strange_items = effluent[column_name].str.contains('<' , na=False)\n",
    "effluent = effluent[strange_items==False]\n",
    "\n",
    "\n",
    "if USE_XLS:\n",
    "    effluent['date'] = pd.to_datetime(effluent['Datum'], format='%d-%m-%Y').dt.date\n",
    "    influent['date'] = pd.to_datetime(influent['Datum'], format='%d-%m-%Y').dt.date\n",
    "else:\n",
    "    effluent['date'] = pd.to_datetime(effluent['Datum'], format='%m/%d/%y').dt.date\n",
    "    influent['date'] = pd.to_datetime(influent['Datum'], format='%m/%d/%y').dt.date\n",
    "    \n",
    "effluent.set_index('date')\n",
    "influent.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=pd.merge(influent,effluent,on=['Datum'], how='outer',suffixes=(\"_inf\",\"_eff\"))\n",
    "result\n",
    "result.set_index(\"date_inf\")\n",
    "#selection=result[pd.isnull(result).any(axis=1)]\n",
    "\n",
    "#selection.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"influent:\",influent.shape)\n",
    "print(\"effluent:\",effluent.shape)\n",
    "print(\"result:\",result.shape)\n",
    "result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(16, 4)) \n",
    "plt.plot(result.Datum,result[column_name+\"_inf\"])\n",
    "plt.plot(result.Datum,result[column_name+\"_eff\"])\n",
    "plt.title(column_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3. Select some data</p></h2>\n",
    "Now, let us make a selection of the data and show this.\n",
    "\n",
    "\n",
    "### a. Pick a garage_id, and a time_window as described below.\n",
    "from_datetime=\"2016-01-01 00:00:00\"\n",
    "\n",
    "to_datetime=\"2016-03-01 00:00:00\"\n",
    "\n",
    "garage_id=36\n",
    "\n",
    "\n",
    "### b. Filter the dataframe using these dates and garage_id. \n",
    "### c. See if the filtering worked and check how many lines remain in the filtered dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_datetime=\"2016-01-01 00:00:00\"\n",
    "to_datetime=\"2016-03-01 00:00:00\"\n",
    "garage_id=36\n",
    "# create a date_time column, and filter using a 'mask' \n",
    "visitors_per_day['visit_datetime'] = pd.to_datetime(visitors_per_day['visit_date'])\n",
    "mask = (visitors_per_day['visit_datetime']>=from_datetime) & (visitors_per_day['visit_datetime'] <= to_datetime) & (visitors_per_day['garage_id']==garage_id)\n",
    "# not necessary, but one is allowed to remove that superfluous column here\n",
    "#visitors_per_day=visitors_per_day.drop(['visit_datetime'], axis=1)\n",
    "selected= visitors_per_day.loc[mask]\n",
    "print(\"from\", from_datetime,\"to\",to_datetime,\"aantal:\",len(selected))\n",
    "selected.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>4. Calculate a rolling mean of visitors</h2>\n",
    "Use the **filtered dataset** from the previous question. \n",
    "\n",
    "### a. Make sure you understand the concept of a rolling mean. \n",
    "A *rolling mean* is also called called *moving average*. See https://en.wikipedia.org/wiki/Moving_average for an explanation.\n",
    "\n",
    "### b. Compute the rolling mean on the count of transactions per day per garage. \n",
    "See https://stackoverflow.com/questions/15771472/pandas-rolling-mean-by-time-interval on how to implement a rolling mean in pandas. Choose a proper window size. \n",
    "\n",
    "### c. Show the number of visits in a graph.\n",
    "Plot the total amount of visitors on a given day in a plot. Add the rolling mean to the same plot. Use matplotlib's *plot* function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_rolling_mean=selected.copy()\n",
    "with_rolling_mean['RollingMean']=with_rolling_mean['count_transactions'].rolling(window=7).mean()\n",
    "with_rolling_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "fig = plt.figure(figsize=(16, 4)) \n",
    "plt.plot(with_rolling_mean['count_transactions'])\n",
    "plt.plot(with_rolling_mean['RollingMean'])\n",
    "plt.title(\"# visits per day\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>5. Draw some graphs</h2>\n",
    "\n",
    "### a. Add date features\n",
    "Add the year, week, month, day, day of year and day of the week as features. Use the corresponding functions from *datetime*.\n",
    "### b. Make graphs per month for all garages\n",
    "For each month, make a separate plot with separate lines for each garage to show the trend of the number of visitors. Color some dots systematically so you can detect a pattern (for example, give each monday a different color than the other dots).\n",
    "\n",
    "Do you see a pattern?\n",
    "\n",
    "### c. Make a graph per weekday per garage. \n",
    "Count the total transactions per weekday.  Make a plot with the days of the week on the x-axis, the number of transactions on the y-axis, and a separate line for each garage to show the week pattern. \n",
    "\n",
    "### d. Make a graph per hour per garage.\n",
    "Same as in c., but now use hour instead of weekday. So, the x-axis will consists of all 24 hours in a day. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visitors_per_day['visit_datetime'] = pd.to_datetime(visitors_per_day['visit_date'])\n",
    "visitors_per_day['year']=visitors_per_day.visit_datetime.dt.year\n",
    "visitors_per_day['week']=visitors_per_day.visit_datetime.dt.week\n",
    "visitors_per_day['month']=visitors_per_day.visit_datetime.dt.month\n",
    "visitors_per_day['day']=visitors_per_day.visit_datetime.dt.day\n",
    "visitors_per_day['dayofyear']=visitors_per_day.visit_datetime.dt.dayofyear\n",
    "visitors_per_day['weekday']=visitors_per_day.visit_datetime.dt.weekday\n",
    "visitors_per_day.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for year in range(2016,2017+1):\n",
    "    for month in range(1,12+1):\n",
    "        fig = plt.figure(figsize=(16, 4))   \n",
    "        for garage_id in parking_locations.garage_id.unique():\n",
    "            mask = (visitors_per_day['month']==month) & (visitors_per_day['year']==year) & (visitors_per_day['garage_id']==garage_id)\n",
    "            data= visitors_per_day.loc[mask]\n",
    "            plt.plot(data['visit_date'],data['count_transactions'])\n",
    "            plt.plot(data['visit_date'],data['count_transactions'],\"bo\")\n",
    "            saturdays=data[data['weekday']==6]\n",
    "            sundays=data[data['weekday']==0]\n",
    "            plt.plot(saturdays['visit_date'],saturdays['count_transactions'],\"ro\")\n",
    "            plt.plot(sundays['visit_date'],sundays['count_transactions'],\"go\")\n",
    "        plt.title(str(year)+\":\"+str(month))\n",
    "        plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parking_transactions['weekday_name'] = parking_transactions['visit_datetime'].dt.weekday_name\n",
    "visitors_per_weekday = parking_transactions.groupby(['weekday_name','garage_id'])['transaction_id'].count().rename(columns={'transaction_id':'count_transactions'})\n",
    "visitors_per_weekday.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visitors_per_weekday.plot(title=\"sum #transactions per day for each garage\", kind=\"bar\",figsize=(16,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parking_transactions['weekday'] = parking_transactions['visit_datetime'].dt.weekday\n",
    "visitors_per_weekday = parking_transactions.groupby(['weekday','garage_id','weekday_name'],as_index=False)['transaction_id'].count().rename(columns={'transaction_id':'count_transactions'})\n",
    "visitors_per_weekday.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 4))  \n",
    "ax = fig.add_subplot(111)\n",
    "plt.title(\"visits per weekday\")\n",
    "for garage_id in parking_locations.garage_id.unique():\n",
    "    mask =(visitors_per_weekday['garage_id']==garage_id)\n",
    "    data= visitors_per_weekday.loc[mask]\n",
    "    plt.plot(data['weekday'],data['count_transactions'],label=str(garage_id))\n",
    "    ax.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>and now... per hour instead of per day</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parking_transactions['hour'] = parking_transactions['visit_datetime'].dt.hour\n",
    "visitors_per_hour = parking_transactions.groupby(['hour','garage_id'])['transaction_id'].count().rename(columns={'transaction_id':'count_transactions'})\n",
    "visitors_per_hour.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visitors_per_hour.plot(title=\"sum count #transactions per hour for each garage divided by capacity of garage\",kind=\"bar\",figsize=(16,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visitors_per_hour = parking_transactions.groupby(['garage_id','hour'],as_index=False)['transaction_id'].count().rename(columns={'transaction_id':'count_transactions'})\n",
    "fig = plt.figure(figsize=(16, 4))  \n",
    "ax = fig.add_subplot(111)\n",
    "plt.title(\"visits per hour\")\n",
    "for garage_id in parking_locations.garage_id.unique():\n",
    "    mask =(visitors_per_hour['garage_id']==garage_id)\n",
    "    data= visitors_per_hour.loc[mask]\n",
    "    plt.plot(data['hour'],data['count_transactions'],label=str(garage_id))\n",
    "    ax.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visitors_per_hour = parking_transactions.groupby(['garage_id','hour','weekday'],as_index=False)['transaction_id'].count().rename(columns={'transaction_id':'count_transactions'})\n",
    "for weekday in range(0,6+1):\n",
    "    fig = plt.figure(figsize=(16, 4))  \n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.title(\"visits per hour for weekday \"+str(weekday))\n",
    "    for garage_id in parking_locations.garage_id.unique():\n",
    "        mask =(visitors_per_hour['garage_id']==garage_id) & (visitors_per_hour['weekday']==weekday)\n",
    "        data= visitors_per_hour.loc[mask]\n",
    "        plt.plot(data['hour'],data['count_transactions'],label=str(garage_id))\n",
    "        ax.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>6. Perform clustering on locations </h2>\n",
    "As a simple test with clustering, we will inspect the latitude and longitude of the parking locations and perform K-Means clustering on this. \n",
    "\n",
    "### a. Plot the latitude versus the longitude of the parking locations. \n",
    "\n",
    "### b. Perform K-Means clustering on this\n",
    "Perform the following steps:\n",
    "<p>\n",
    "    <ol>\n",
    "<li>Perform K-means clustering on the dataset using the *KMeans* function from sklearn.cluster. We would like to create two groups (just for demonstrating now) so the number of clusters *k* in the algorithm is two. </li>\n",
    "<li>Perform a prediction using *predict()* on the data set. </li>\n",
    "<li>Show the results by coloring each dot in the scatterplot  </li>\n",
    "\n",
    "    </ol>\n",
    "</p>\n",
    "\n",
    "\n",
    "### c. Add the column with the cluster number to the dataset and save it to csv\n",
    "Call the result 'clusters.csv', for example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(parking_locations.latitude, parking_locations.longitude,'co')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parking_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parking_locations[['latitude', 'longitude']] = parking_locations[['latitude', 'longitude']].astype(float)\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "X =parking_locations[['latitude','longitude']] \n",
    "k_means=KMeans(n_clusters=2,random_state=0)\n",
    "k_means.fit(X)\n",
    "\n",
    "cluster_values=k_means.predict(X)\n",
    "fig = plt.figure(figsize=(6, 4)) \n",
    "plt.title(\"parking locations\",size=15)\n",
    "plt.scatter(X.latitude,X.longitude,c=cluster_values,s=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parking_locations['cluster']=cluster_values\n",
    "parking_locations['labels'] = k_means.labels_\n",
    "parking_locations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parking_locations.to_csv(\"../data/out-clusters.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra information about the groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_groups = parking_locations.groupby('labels')\n",
    "for name, group in label_groups:\n",
    "    print(name) \n",
    "    print(group.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Done!\n",
    "This is the end of tutorial 1. In the next tutorial, we will do the data preparation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
