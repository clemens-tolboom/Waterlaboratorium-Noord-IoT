{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2>Exploration (get a very first feeling of the data)</h2>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "This is a copy of `wico-explore01.ipynb` for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name='zwst (mg/l)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kennisnetwerk_data_WWTPpopulaties_WLN.xlsx\r\n",
      "Kennisnetwerk_procesdata_kwaliteitsdata_WLN.xlsx\r\n",
      "README.MD\r\n",
      "begeleidende tekst data casus WLN.docx\r\n",
      "uurgeg_277_2011-2020.txt\r\n",
      "uurgeg_277_2011-2020_KNMI_Lauwersoog.zip\r\n",
      "uurgeg_280_2011-2020.txt\r\n",
      "uurgeg_280_2011-2020_KNMI_Eelde.zip\r\n",
      "uurgeg_285_2011-2020.txt\r\n",
      "uurgeg_285_2011-2020_KNMI_Huibertgat.zip\r\n",
      "uurgeg_286_2011-2020.txt\r\n",
      "uurgeg_286_2011-2020_KNMI_Nieuw_Beerta.zip\r\n"
     ]
    }
   ],
   "source": [
    "XLS_DIR='../../Waterlaboratorium-Noord-IoT/Data/'\n",
    "%ls $XLS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-read-data.ipynb\r\n",
      "Pipfile\r\n",
      "Pipfile.lock\r\n",
      "README.MD\r\n",
      "altair-data-a7058e0c6f5119308fc517a83fa03339.json\r\n",
      "altair-test.ipynb\r\n",
      "clemens-01.ipynb\r\n",
      "clemens-02.ipynb\r\n",
      "clemens-03.ipynb\r\n",
      "clemens-04.ipynb\r\n",
      "\u001b[34mdata\u001b[m\u001b[m/\r\n",
      "\u001b[34mdocs\u001b[m\u001b[m/\r\n",
      "inne-01.ipynb\r\n",
      "read_and_explore.ipynb\r\n",
      "wico-explore01.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "# This result in current dir as $DATA_DIR is empty\n",
    "%ls $DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mKennisnetwerk_procesdata_kwaliteitsdata_WLN\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "CSV_DIR='../../ds-wln/datasets/'\n",
    "%ls $CSV_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_XLS=False\n",
    "\n",
    "if USE_XLS:\n",
    "    # This will result in XLRDError: Can't find workbook in OLE2 compound document\n",
    "    orig_influent = pd.read_excel(XLS_DIR + \"Kennisnetwerk_procesdata_kwaliteitsdata_WLN.xlsx\", sheet_name='Influent lab analyses')\n",
    "    orig_effluent=pd.read_excel(DATA_DIR + \"Kennisnetwerk_procesdata_kwaliteitsdata_WLN.xlsx\", sheet_name='effl. lab analyses')\n",
    "\n",
    "else:\n",
    "    orig_influent = pd.read_csv(CSV_DIR + 'Kennisnetwerk_procesdata_kwaliteitsdata_WLN/' + 'Influent lab analyses.csv', sep=',', decimal ='.')\n",
    "    orig_effluent = pd.read_csv(CSV_DIR + 'Kennisnetwerk_procesdata_kwaliteitsdata_WLN/' + 'effl. lab analyses.csv', sep=',', decimal ='.')\n",
    "    # We need to convert date field(s) from m/d/y as these are exported by CSV and not by Excel above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch Datum and our target column_name\n",
    "orig_influent = orig_influent[['Datum', column_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datum</th>\n",
       "      <th>zwst (mg/l)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/01/14</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/06/14</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/11/14</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/16/14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/21/14</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Datum zwst (mg/l)\n",
       "0  10/01/14          17\n",
       "1  10/06/14           7\n",
       "2  10/11/14          39\n",
       "3  10/16/14          15\n",
       "4  10/21/14          11"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_effluent=orig_effluent[['Datum', column_name]]\n",
    "\n",
    "orig_effluent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data '10/01/14' does not match format '%d-%m-%Y' (match)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/.local/share/virtualenvs/Team1-9K3ihJ0V/lib/python3.6/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike\u001b[0;34m(arg, box, format, name, tz)\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                 \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime_to_datetime64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mDatetimeIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslibs/conversion.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.conversion.datetime_to_datetime64\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Unrecognized value type: <class 'str'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-dba039621799>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#effluent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0meffluent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meffluent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Datum'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%d-%m-%Y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0minfluent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfluent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Datum'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%d-%m-%Y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0meffluent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Team1-9K3ihJ0V/lib/python3.6/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, box, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mABCDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMutableMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Team1-9K3ihJ0V/lib/python3.6/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike\u001b[0;34m(arg, box, format, name, tz)\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mDatetimeIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Team1-9K3ihJ0V/lib/python3.6/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike\u001b[0;34m(arg, box, format, name, tz)\u001b[0m\n\u001b[1;32m    345\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                         result = array_strptime(arg, format, exact=exact,\n\u001b[0;32m--> 347\u001b[0;31m                                                 errors=errors)\n\u001b[0m\u001b[1;32m    348\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mtslib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfBoundsDatetime\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'raise'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslibs/strptime.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: time data '10/01/14' does not match format '%d-%m-%Y' (match)"
     ]
    }
   ],
   "source": [
    "effluent=orig_effluent.copy()\n",
    "influent=orig_influent.copy()\n",
    "\n",
    "# opruimen maffe velden\n",
    "strange_items = effluent[column_name].str.contains('<' , na=False)\n",
    "effluent = effluent[strange_items==False]\n",
    "\n",
    "influent=orig_influent.copy()\n",
    "#effluent\n",
    "\n",
    "effluent['date'] = pd.to_datetime(effluent['Datum'], format='%d-%m-%Y').dt.date\n",
    "influent['date'] = pd.to_datetime(influent['Datum'], format='%d-%m-%Y').dt.date\n",
    "effluent.set_index('date')\n",
    "influent.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=pd.merge(influent,effluent,on=['Datum'], how='outer',suffixes=(\"_inf\",\"_eff\"))\n",
    "result\n",
    "result.set_index(\"date_inf\")\n",
    "#selection=result[pd.isnull(result).any(axis=1)]\n",
    "\n",
    "#selection.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"influent:\",influent.shape)\n",
    "print(\"effluent:\",effluent.shape)\n",
    "print(\"result:\",result.shape)\n",
    "result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(16, 4)) \n",
    "plt.plot(result.Datum,result[column_name+\"_inf\"])\n",
    "plt.plot(result.Datum,result[column_name+\"_eff\"])\n",
    "plt.title(column_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3. Select some data</p></h2>\n",
    "Now, let us make a selection of the data and show this.\n",
    "\n",
    "\n",
    "### a. Pick a garage_id, and a time_window as described below.\n",
    "from_datetime=\"2016-01-01 00:00:00\"\n",
    "\n",
    "to_datetime=\"2016-03-01 00:00:00\"\n",
    "\n",
    "garage_id=36\n",
    "\n",
    "\n",
    "### b. Filter the dataframe using these dates and garage_id. \n",
    "### c. See if the filtering worked and check how many lines remain in the filtered dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_datetime=\"2016-01-01 00:00:00\"\n",
    "to_datetime=\"2016-03-01 00:00:00\"\n",
    "garage_id=36\n",
    "# create a date_time column, and filter using a 'mask' \n",
    "visitors_per_day['visit_datetime'] = pd.to_datetime(visitors_per_day['visit_date'])\n",
    "mask = (visitors_per_day['visit_datetime']>=from_datetime) & (visitors_per_day['visit_datetime'] <= to_datetime) & (visitors_per_day['garage_id']==garage_id)\n",
    "# not necessary, but one is allowed to remove that superfluous column here\n",
    "#visitors_per_day=visitors_per_day.drop(['visit_datetime'], axis=1)\n",
    "selected= visitors_per_day.loc[mask]\n",
    "print(\"from\", from_datetime,\"to\",to_datetime,\"aantal:\",len(selected))\n",
    "selected.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>4. Calculate a rolling mean of visitors</h2>\n",
    "Use the **filtered dataset** from the previous question. \n",
    "\n",
    "### a. Make sure you understand the concept of a rolling mean. \n",
    "A *rolling mean* is also called called *moving average*. See https://en.wikipedia.org/wiki/Moving_average for an explanation.\n",
    "\n",
    "### b. Compute the rolling mean on the count of transactions per day per garage. \n",
    "See https://stackoverflow.com/questions/15771472/pandas-rolling-mean-by-time-interval on how to implement a rolling mean in pandas. Choose a proper window size. \n",
    "\n",
    "### c. Show the number of visits in a graph.\n",
    "Plot the total amount of visitors on a given day in a plot. Add the rolling mean to the same plot. Use matplotlib's *plot* function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_rolling_mean=selected.copy()\n",
    "with_rolling_mean['RollingMean']=with_rolling_mean['count_transactions'].rolling(window=7).mean()\n",
    "with_rolling_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "fig = plt.figure(figsize=(16, 4)) \n",
    "plt.plot(with_rolling_mean['count_transactions'])\n",
    "plt.plot(with_rolling_mean['RollingMean'])\n",
    "plt.title(\"# visits per day\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>5. Draw some graphs</h2>\n",
    "\n",
    "### a. Add date features\n",
    "Add the year, week, month, day, day of year and day of the week as features. Use the corresponding functions from *datetime*.\n",
    "### b. Make graphs per month for all garages\n",
    "For each month, make a separate plot with separate lines for each garage to show the trend of the number of visitors. Color some dots systematically so you can detect a pattern (for example, give each monday a different color than the other dots).\n",
    "\n",
    "Do you see a pattern?\n",
    "\n",
    "### c. Make a graph per weekday per garage. \n",
    "Count the total transactions per weekday.  Make a plot with the days of the week on the x-axis, the number of transactions on the y-axis, and a separate line for each garage to show the week pattern. \n",
    "\n",
    "### d. Make a graph per hour per garage.\n",
    "Same as in c., but now use hour instead of weekday. So, the x-axis will consists of all 24 hours in a day. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visitors_per_day['visit_datetime'] = pd.to_datetime(visitors_per_day['visit_date'])\n",
    "visitors_per_day['year']=visitors_per_day.visit_datetime.dt.year\n",
    "visitors_per_day['week']=visitors_per_day.visit_datetime.dt.week\n",
    "visitors_per_day['month']=visitors_per_day.visit_datetime.dt.month\n",
    "visitors_per_day['day']=visitors_per_day.visit_datetime.dt.day\n",
    "visitors_per_day['dayofyear']=visitors_per_day.visit_datetime.dt.dayofyear\n",
    "visitors_per_day['weekday']=visitors_per_day.visit_datetime.dt.weekday\n",
    "visitors_per_day.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for year in range(2016,2017+1):\n",
    "    for month in range(1,12+1):\n",
    "        fig = plt.figure(figsize=(16, 4))   \n",
    "        for garage_id in parking_locations.garage_id.unique():\n",
    "            mask = (visitors_per_day['month']==month) & (visitors_per_day['year']==year) & (visitors_per_day['garage_id']==garage_id)\n",
    "            data= visitors_per_day.loc[mask]\n",
    "            plt.plot(data['visit_date'],data['count_transactions'])\n",
    "            plt.plot(data['visit_date'],data['count_transactions'],\"bo\")\n",
    "            saturdays=data[data['weekday']==6]\n",
    "            sundays=data[data['weekday']==0]\n",
    "            plt.plot(saturdays['visit_date'],saturdays['count_transactions'],\"ro\")\n",
    "            plt.plot(sundays['visit_date'],sundays['count_transactions'],\"go\")\n",
    "        plt.title(str(year)+\":\"+str(month))\n",
    "        plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parking_transactions['weekday_name'] = parking_transactions['visit_datetime'].dt.weekday_name\n",
    "visitors_per_weekday = parking_transactions.groupby(['weekday_name','garage_id'])['transaction_id'].count().rename(columns={'transaction_id':'count_transactions'})\n",
    "visitors_per_weekday.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visitors_per_weekday.plot(title=\"sum #transactions per day for each garage\", kind=\"bar\",figsize=(16,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parking_transactions['weekday'] = parking_transactions['visit_datetime'].dt.weekday\n",
    "visitors_per_weekday = parking_transactions.groupby(['weekday','garage_id','weekday_name'],as_index=False)['transaction_id'].count().rename(columns={'transaction_id':'count_transactions'})\n",
    "visitors_per_weekday.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 4))  \n",
    "ax = fig.add_subplot(111)\n",
    "plt.title(\"visits per weekday\")\n",
    "for garage_id in parking_locations.garage_id.unique():\n",
    "    mask =(visitors_per_weekday['garage_id']==garage_id)\n",
    "    data= visitors_per_weekday.loc[mask]\n",
    "    plt.plot(data['weekday'],data['count_transactions'],label=str(garage_id))\n",
    "    ax.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>and now... per hour instead of per day</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parking_transactions['hour'] = parking_transactions['visit_datetime'].dt.hour\n",
    "visitors_per_hour = parking_transactions.groupby(['hour','garage_id'])['transaction_id'].count().rename(columns={'transaction_id':'count_transactions'})\n",
    "visitors_per_hour.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visitors_per_hour.plot(title=\"sum count #transactions per hour for each garage divided by capacity of garage\",kind=\"bar\",figsize=(16,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visitors_per_hour = parking_transactions.groupby(['garage_id','hour'],as_index=False)['transaction_id'].count().rename(columns={'transaction_id':'count_transactions'})\n",
    "fig = plt.figure(figsize=(16, 4))  \n",
    "ax = fig.add_subplot(111)\n",
    "plt.title(\"visits per hour\")\n",
    "for garage_id in parking_locations.garage_id.unique():\n",
    "    mask =(visitors_per_hour['garage_id']==garage_id)\n",
    "    data= visitors_per_hour.loc[mask]\n",
    "    plt.plot(data['hour'],data['count_transactions'],label=str(garage_id))\n",
    "    ax.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visitors_per_hour = parking_transactions.groupby(['garage_id','hour','weekday'],as_index=False)['transaction_id'].count().rename(columns={'transaction_id':'count_transactions'})\n",
    "for weekday in range(0,6+1):\n",
    "    fig = plt.figure(figsize=(16, 4))  \n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.title(\"visits per hour for weekday \"+str(weekday))\n",
    "    for garage_id in parking_locations.garage_id.unique():\n",
    "        mask =(visitors_per_hour['garage_id']==garage_id) & (visitors_per_hour['weekday']==weekday)\n",
    "        data= visitors_per_hour.loc[mask]\n",
    "        plt.plot(data['hour'],data['count_transactions'],label=str(garage_id))\n",
    "        ax.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>6. Perform clustering on locations </h2>\n",
    "As a simple test with clustering, we will inspect the latitude and longitude of the parking locations and perform K-Means clustering on this. \n",
    "\n",
    "### a. Plot the latitude versus the longitude of the parking locations. \n",
    "\n",
    "### b. Perform K-Means clustering on this\n",
    "Perform the following steps:\n",
    "<p>\n",
    "    <ol>\n",
    "<li>Perform K-means clustering on the dataset using the *KMeans* function from sklearn.cluster. We would like to create two groups (just for demonstrating now) so the number of clusters *k* in the algorithm is two. </li>\n",
    "<li>Perform a prediction using *predict()* on the data set. </li>\n",
    "<li>Show the results by coloring each dot in the scatterplot  </li>\n",
    "\n",
    "    </ol>\n",
    "</p>\n",
    "\n",
    "\n",
    "### c. Add the column with the cluster number to the dataset and save it to csv\n",
    "Call the result 'clusters.csv', for example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(parking_locations.latitude, parking_locations.longitude,'co')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parking_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parking_locations[['latitude', 'longitude']] = parking_locations[['latitude', 'longitude']].astype(float)\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "X =parking_locations[['latitude','longitude']] \n",
    "k_means=KMeans(n_clusters=2,random_state=0)\n",
    "k_means.fit(X)\n",
    "\n",
    "cluster_values=k_means.predict(X)\n",
    "fig = plt.figure(figsize=(6, 4)) \n",
    "plt.title(\"parking locations\",size=15)\n",
    "plt.scatter(X.latitude,X.longitude,c=cluster_values,s=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parking_locations['cluster']=cluster_values\n",
    "parking_locations['labels'] = k_means.labels_\n",
    "parking_locations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parking_locations.to_csv(\"../data/out-clusters.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra information about the groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_groups = parking_locations.groupby('labels')\n",
    "for name, group in label_groups:\n",
    "    print(name) \n",
    "    print(group.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Done!\n",
    "This is the end of tutorial 1. In the next tutorial, we will do the data preparation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
